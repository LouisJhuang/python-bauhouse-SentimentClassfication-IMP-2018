{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Few Preprocessings**\n",
    "# **2. Model: FastText by Keras**\n",
    "## **2.1** Change Preprocessings:\n",
    "- Do lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(7)\n",
    "# 函數可以保證生成的隨機數具有可預測性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./keras_fasttext_data/train.zip')\n",
    "a2c = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n",
    "y = np.array([a2c[a] for a in df.author])\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Few Preprocessings**\n",
    "\n",
    "In traditional NLP tasks, preprocessings play an important role, but...\n",
    "\n",
    "## **Low-frequency words**\n",
    "In my experience, fastText is very fast, but I need to delete rare words to avoid overfitting.\n",
    "\n",
    "**NOTE**:\n",
    "Some keywords are rare words, such like *Cthulhu* in *Cthulhu Mythos* of *Howard Phillips Lovecraft*.\n",
    "But these are useful for this task.\n",
    "\n",
    "## **Removing Stopwords**\n",
    "\n",
    "Nothing.\n",
    "To identify author from a sentence, some stopwords play an important role because one has specific usages of them.\n",
    "\n",
    "## **Stemming and Lowercase**\n",
    "\n",
    "Nothing.\n",
    "This reason is the same for stopwords removing.\n",
    "And I guess some stemming rules provided by libraries is bad for this task because all author is the older author.\n",
    "\n",
    "## **Cutting long sentence**\n",
    "\n",
    "Too long documents are cut.\n",
    "\n",
    "## **Punctuation**\n",
    "\n",
    "Because I guess each author has unique punctuations's usage in the novel, I separate them from words.\n",
    "\n",
    "e.g. `Don't worry` -> `Don ' t worry`\n",
    "\n",
    "## **Is it slow?**\n",
    "\n",
    "Don't worry! FastText is a very fast algorithm if it runs on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c EAP   MWS   HPL   \n",
      ". 8406 5761 5908 \n",
      "a 68525 55274 56815 \n",
      "V 156 57 67 \n",
      "J 164 66 210 \n",
      "O 414 282 503 \n",
      "l 35371 27819 30273 \n",
      "A 1258 943 1167 \n",
      ": 176 339 47 \n",
      "j 683 682 424 \n",
      "B 835 395 533 \n",
      "s 53841 45962 43915 \n",
      "ä 1 0 6 \n",
      "ç 1 0 0 \n",
      "h 51580 43738 42770 \n",
      "\" 2987 1469 513 \n",
      "Z 23 2 51 \n",
      "Æ 1 0 4 \n",
      "H 864 669 741 \n",
      "I 4846 4917 3480 \n",
      "N 411 204 345 \n",
      "i 60952 46080 44250 \n",
      "Q 21 7 10 \n",
      ", 17594 12045 8581 \n",
      "c 24127 17911 18338 \n",
      "ï 0 0 7 \n",
      "Υ 0 0 1 \n",
      "t 82426 63142 62235 \n",
      "ô 8 0 0 \n",
      "w 17507 16062 15554 \n",
      "v 9624 7948 6529 \n",
      "ö 16 0 3 \n",
      "m 22792 20471 17622 \n",
      "P 442 365 320 \n",
      "æ 36 0 10 \n",
      "δ 0 0 2 \n",
      "ë 0 0 12 \n",
      "ἶ 0 0 2 \n",
      "k 4277 3707 5204 \n",
      "T 2217 1230 1583 \n",
      "E 435 445 281 \n",
      "M 1065 415 645 \n",
      "X 17 4 5 \n",
      "à 10 0 0 \n",
      "L 458 307 249 \n",
      "b 13245 9611 10636 \n",
      "D 491 227 334 \n",
      "ê 28 0 2 \n",
      "C 395 308 439 \n",
      "y 17001 14877 12534 \n",
      "o 67145 53386 50996 \n",
      "é 47 0 15 \n",
      "Π 0 0 1 \n",
      "S 729 578 841 \n",
      "Σ 0 0 1 \n",
      "g 16088 12601 14951 \n",
      "; 1354 2662 1143 \n",
      "f 22354 18351 16272 \n",
      "U 166 46 94 \n",
      "Ο 0 0 3 \n",
      "p 17422 12361 10965 \n",
      "î 1 0 0 \n",
      "ñ 0 0 7 \n",
      "n 62636 50291 50879 \n",
      "' 1334 476 1710 \n",
      "G 313 246 318 \n",
      "K 86 35 176 \n",
      "u 26311 21025 19519 \n",
      "ü 1 0 5 \n",
      "Y 282 234 111 \n",
      "? 510 419 169 \n",
      "e 114885 97515 88259 \n",
      "è 15 0 0 \n",
      "W 739 681 732 \n",
      "d 36862 35315 33366 \n",
      "r 51221 44042 40590 \n",
      "Å 0 0 1 \n",
      "z 634 400 529 \n",
      "x 1951 1267 1061 \n",
      "α 0 0 2 \n",
      "Ν 0 0 1 \n",
      "q 1030 677 779 \n",
      "R 258 385 237 \n",
      "F 383 232 269 \n",
      "â 6 0 0 \n"
     ]
    }
   ],
   "source": [
    "counter = {name : defaultdict(int) for name in set(df.author)}\n",
    "for (text, author) in zip(df.text, df.author):\n",
    "    text = text.replace(' ', '')\n",
    "    for c in text:\n",
    "        counter[author][c] += 1\n",
    "\n",
    "chars = set()\n",
    "for v in counter.values():\n",
    "    chars |= v.keys()\n",
    "    \n",
    "names = [author for author in counter.keys()]\n",
    "\n",
    "print('c ', end='')\n",
    "for n in names:\n",
    "    print(n, end='   ')\n",
    "print()\n",
    "for c in chars:    \n",
    "    print(c, end=' ')\n",
    "    for n in names:\n",
    "        print(counter[n][c], end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary of character distribution**\n",
    "\n",
    "- HPL and EAP used non ascii characters like a `ä`.\n",
    "- The number of punctuations seems to be good feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "My preproceeings are \n",
    "\n",
    "- Separate punctuation from words\n",
    "- Remove lower frequency words ( <= 2)\n",
    "- Cut a longer document which contains `256` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    signs = set(',.:;\"?!')\n",
    "    prods = set(text) & signs\n",
    "    if not prods:\n",
    "        return text\n",
    "\n",
    "    for sign in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_docs(df, n_gram_max=2):\n",
    "    def add_ngram(q, n_gram_max):\n",
    "            ngrams = []\n",
    "            for n in range(2, n_gram_max+1):\n",
    "                for w_index in range(len(q)-n+1):\n",
    "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n",
    "            return q + ngrams\n",
    "        \n",
    "    docs = []\n",
    "    for doc in df.text:\n",
    "        doc = preprocess(doc).split()\n",
    "        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "\n",
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=False, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=False, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Model: FastText by Keras**\n",
    "\n",
    "FastText is very fast and strong baseline algorithm for text classification based on Continuous Bag-of-Words model a.k.a Word2vec.\n",
    "\n",
    "FastText contains only three layers:\n",
    "\n",
    "1. Embeddings layer: Input words (and word n-grams) are all words in a sentence/document\n",
    "2. Mean/AveragePooling Layer: Taking average vector of Embedding vectors\n",
    "3. Softmax layer\n",
    "\n",
    "There are some implementations of FastText:\n",
    "\n",
    "- Original library provided by Facebook AI research: https://github.com/facebookresearch/fastText\n",
    "- Keras: https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py\n",
    "- Gensim: https://radimrehurek.com/gensim/models/wrappers/fasttext.html\n",
    "\n",
    "Original Paper: https://arxiv.org/abs/1607.01759 : More detail information about fastText classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My FastText parameters are:\n",
    "\n",
    "- The dimension of word vector is 20\n",
    "- Optimizer is `Adam`\n",
    "- Inputs are words and word bi-grams\n",
    "  - you can change this parameter by passing the max n-gram size to argument of `create_docs` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = np.max(docs) + 1\n",
    "embedding_dims = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(embedding_dims=20, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 1.0678 - acc: 0.4075 - val_loss: 1.0307 - val_acc: 0.4535\n",
      "Epoch 2/25\n",
      "15663/15663 [==============================] - 32s 2ms/step - loss: 0.9350 - acc: 0.6098 - val_loss: 0.8613 - val_acc: 0.7142\n",
      "Epoch 3/25\n",
      "15663/15663 [==============================] - 39s 2ms/step - loss: 0.7280 - acc: 0.7850 - val_loss: 0.7093 - val_acc: 0.7554\n",
      "Epoch 4/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 0.5687 - acc: 0.8461 - val_loss: 0.6116 - val_acc: 0.7868\n",
      "Epoch 5/25\n",
      "15663/15663 [==============================] - 43s 3ms/step - loss: 0.4550 - acc: 0.8794 - val_loss: 0.5420 - val_acc: 0.8036\n",
      "Epoch 6/25\n",
      "15663/15663 [==============================] - 37s 2ms/step - loss: 0.3687 - acc: 0.9061 - val_loss: 0.4893 - val_acc: 0.8192\n",
      "Epoch 7/25\n",
      "15663/15663 [==============================] - 39s 2ms/step - loss: 0.3009 - acc: 0.9275 - val_loss: 0.4521 - val_acc: 0.8297\n",
      "Epoch 8/25\n",
      "15663/15663 [==============================] - 38s 2ms/step - loss: 0.2467 - acc: 0.9441 - val_loss: 0.4204 - val_acc: 0.8447\n",
      "Epoch 9/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 0.2026 - acc: 0.9574 - val_loss: 0.3992 - val_acc: 0.8450\n",
      "Epoch 10/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 0.1668 - acc: 0.9663 - val_loss: 0.3864 - val_acc: 0.8475\n",
      "Epoch 11/25\n",
      "15663/15663 [==============================] - 32s 2ms/step - loss: 0.1369 - acc: 0.9742 - val_loss: 0.3669 - val_acc: 0.8593\n",
      "Epoch 12/25\n",
      "15663/15663 [==============================] - 28s 2ms/step - loss: 0.1128 - acc: 0.9800 - val_loss: 0.3601 - val_acc: 0.8631\n",
      "Epoch 13/25\n",
      "15663/15663 [==============================] - 42s 3ms/step - loss: 0.0928 - acc: 0.9848 - val_loss: 0.3489 - val_acc: 0.8682\n",
      "Epoch 14/25\n",
      "15663/15663 [==============================] - 23s 1ms/step - loss: 0.0770 - acc: 0.9876 - val_loss: 0.3440 - val_acc: 0.8685\n",
      "Epoch 15/25\n",
      "15663/15663 [==============================] - 30s 2ms/step - loss: 0.0635 - acc: 0.9905 - val_loss: 0.3421 - val_acc: 0.8677\n",
      "Epoch 16/25\n",
      "15663/15663 [==============================] - 20s 1ms/step - loss: 0.0527 - acc: 0.9921 - val_loss: 0.3426 - val_acc: 0.8693\n",
      "Epoch 17/25\n",
      "15663/15663 [==============================] - 32s 2ms/step - loss: 0.0437 - acc: 0.9937 - val_loss: 0.3474 - val_acc: 0.8670\n",
      "CPU times: user 3min 34s, sys: 2min 4s, total: 5min 39s\n",
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 25\n",
    "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n",
    "\n",
    "model = create_model()\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=epochs,\n",
    "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.40745706442218627,\n",
       "  0.609844857322251,\n",
       "  0.7850347953890578,\n",
       "  0.8461342016330725,\n",
       "  0.8793973057676319,\n",
       "  0.9060844027363598,\n",
       "  0.9275362318916689,\n",
       "  0.9441358615846261,\n",
       "  0.9574155653488862,\n",
       "  0.966289982761923,\n",
       "  0.9742067292345017,\n",
       "  0.979952754900083,\n",
       "  0.9848049543548237,\n",
       "  0.9875502777245738,\n",
       "  0.9904871352869821,\n",
       "  0.9921470982608444,\n",
       "  0.993679371771666],\n",
       " 'loss': [1.0677945384012362,\n",
       "  0.9350210330476099,\n",
       "  0.7280177331546147,\n",
       "  0.5686626990225202,\n",
       "  0.4549655123573758,\n",
       "  0.3686974758938386,\n",
       "  0.3008757487404646,\n",
       "  0.24674754453323386,\n",
       "  0.202612399660117,\n",
       "  0.1668055929238332,\n",
       "  0.13685051731093134,\n",
       "  0.11276970568323458,\n",
       "  0.09282629702946377,\n",
       "  0.07696351547214915,\n",
       "  0.06346491431530935,\n",
       "  0.052670161264240914,\n",
       "  0.04374515521879672],\n",
       " 'val_acc': [0.45352400411624344,\n",
       "  0.7142492339730384,\n",
       "  0.7553626149740599,\n",
       "  0.7867722164866142,\n",
       "  0.8036261490708839,\n",
       "  0.819203268702354,\n",
       "  0.8296731359137943,\n",
       "  0.8447395301936718,\n",
       "  0.8449948926868186,\n",
       "  0.8475485188359503,\n",
       "  0.8592951991219564,\n",
       "  0.8631256383456541,\n",
       "  0.8682328906439176,\n",
       "  0.8684882532588308,\n",
       "  0.8677221654140913,\n",
       "  0.8692543411035704,\n",
       "  0.8669560775693518],\n",
       " 'val_loss': [1.0306591837837211,\n",
       "  0.8612615294427258,\n",
       "  0.7092895042056083,\n",
       "  0.6115640991798339,\n",
       "  0.541975201759202,\n",
       "  0.4893255080339005,\n",
       "  0.4520896200748946,\n",
       "  0.420354586516995,\n",
       "  0.3992314301240919,\n",
       "  0.38639035939683225,\n",
       "  0.3668912875640137,\n",
       "  0.36005123512128767,\n",
       "  0.34885007445914507,\n",
       "  0.3439852383912401,\n",
       "  0.34207686147175964,\n",
       "  0.34258469844862927,\n",
       "  0.34735384951816517]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.1 Change Preprocessings**\n",
    "\n",
    "Next, I change some parameters and preprocessings to improve fastText model.\n",
    "## **2.1.1 Do lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "\n",
    "input_dim = np.max(docs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/16\n",
      "15663/15663 [==============================] - 81s 5ms/step - loss: 1.0667 - acc: 0.4096 - val_loss: 1.0267 - val_acc: 0.4216\n",
      "Epoch 2/16\n",
      "15663/15663 [==============================] - 80s 5ms/step - loss: 0.9261 - acc: 0.6157 - val_loss: 0.8504 - val_acc: 0.6790\n",
      "Epoch 3/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.7231 - acc: 0.7848 - val_loss: 0.7020 - val_acc: 0.7620\n",
      "Epoch 4/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.5691 - acc: 0.8385 - val_loss: 0.6018 - val_acc: 0.7939\n",
      "Epoch 5/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.4585 - acc: 0.8751 - val_loss: 0.5352 - val_acc: 0.8098\n",
      "Epoch 6/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.3746 - acc: 0.9013 - val_loss: 0.4829 - val_acc: 0.8322\n",
      "Epoch 7/16\n",
      "15663/15663 [==============================] - 79s 5ms/step - loss: 0.3080 - acc: 0.9231 - val_loss: 0.4453 - val_acc: 0.8414\n",
      "Epoch 8/16\n",
      "15663/15663 [==============================] - 79s 5ms/step - loss: 0.2545 - acc: 0.9379 - val_loss: 0.4154 - val_acc: 0.8468\n",
      "Epoch 9/16\n",
      "15663/15663 [==============================] - 79s 5ms/step - loss: 0.2103 - acc: 0.9536 - val_loss: 0.3947 - val_acc: 0.8486\n",
      "Epoch 10/16\n",
      "15663/15663 [==============================] - 79s 5ms/step - loss: 0.1744 - acc: 0.9634 - val_loss: 0.3748 - val_acc: 0.8550\n",
      "Epoch 11/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.1448 - acc: 0.9702 - val_loss: 0.3635 - val_acc: 0.8575\n",
      "Epoch 12/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.1206 - acc: 0.9770 - val_loss: 0.3507 - val_acc: 0.8613\n",
      "Epoch 13/16\n",
      "15663/15663 [==============================] - 77s 5ms/step - loss: 0.0999 - acc: 0.9807 - val_loss: 0.3440 - val_acc: 0.8631\n",
      "Epoch 14/16\n",
      "15663/15663 [==============================] - 78s 5ms/step - loss: 0.0838 - acc: 0.9854 - val_loss: 0.3424 - val_acc: 0.8631\n",
      "Epoch 15/16\n",
      "15663/15663 [==============================] - 79s 5ms/step - loss: 0.0698 - acc: 0.9879 - val_loss: 0.3351 - val_acc: 0.8677\n",
      "Epoch 16/16\n",
      "15663/15663 [==============================] - 77s 5ms/step - loss: 0.0586 - acc: 0.9912 - val_loss: 0.3425 - val_acc: 0.8644\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n",
    "\n",
    "model = create_model()\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=epochs,\n",
    "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./keras_fasttext_data/test.zip')\n",
    "docs = create_docs(test_df)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "y = model.predict_proba(docs)\n",
    "\n",
    "result = pd.read_csv('./keras_fasttext_data/sample_submission.zip')\n",
    "for a, i in a2c.items():\n",
    "    result[a] = y[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('./keras_fasttext_data/kefastText_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4272846e-02, 2.5963726e-02, 9.4976342e-01],\n",
       "       [9.9948221e-01, 5.1771977e-04, 1.2118203e-07],\n",
       "       [8.9132594e-04, 9.9599361e-01, 3.1150738e-03],\n",
       "       ...,\n",
       "       [7.3178154e-01, 1.8311663e-01, 8.5101813e-02],\n",
       "       [6.2676385e-02, 6.6918219e-03, 9.3063182e-01],\n",
       "       [6.0933948e-02, 9.3904918e-01, 1.6923084e-05]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
