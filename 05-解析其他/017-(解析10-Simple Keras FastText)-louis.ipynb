{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Few Preprocessings\n",
    "# 2. Model: FastText by Keras\n",
    "## 2.1 Change Preprocessings:\n",
    "- Do lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(7)\n",
    "# 函數可以保證生成的隨機數具有可預測性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./keras_fasttext_data/train.zip')\n",
    "a2c = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n",
    "# 三個欄位改變成0,1,2\n",
    "y = np.array([a2c[a] for a in df.author])\n",
    "#  np.array 之中的每一個元素都必須是相同型態（相同大小）的\n",
    "#  此時 y.shape = (19579,) 19579個一維陣列\n",
    "\n",
    "y = to_categorical(y)\n",
    "# to_categorical = 將類向量（整数）轉換為二進制類矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]\n",
    "# 轉成三個二維陣列 都是0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最後一個元素\n",
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19579"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#一樣19579 只是變成\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看一下內容\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAP': 0, 'HPL': 1, 'MWS': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三個欄位改變成對應 0,1,2\n",
    "a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 變成字典\n",
    "type(a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查字典\n",
    "a2c['HPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Few Preprocessings**\n",
    "**幾乎沒有前處理**\n",
    "\n",
    "- In traditional NLP tasks, preprocessings play an important role, but...\n",
    "-  在傳統的NLP(自然語言處理)任務 前處理扮演一個重要角色,但是...\n",
    "\n",
    "## **Low-frequency words**\n",
    "** 低頻率單字 **\n",
    "\n",
    "-   In my experience, fastText is very fast, but I need to delete rare words to avoid overfitting.\n",
    "-   在我的經驗中, fasttext 非常快速,但是需要刪除較少出現的單字避免 overfitting\n",
    "\n",
    "**NOTE**:\n",
    "- Some keywords are rare words, such like *Cthulhu* in *Cthulhu Mythos* of *Howard Phillips Lovecraft*.\n",
    "- But these are useful for this task.\n",
    "\n",
    "**NOTE**\n",
    "- 有些較少出現的單字,像是 *Cthulhu* 在 *克蘇魯神話* 出現在 *克蘇魯的召喚*中\n",
    "- 但是對這項任務是有用的\n",
    "\n",
    "## **Removing Stopwords**\n",
    "**刪除停用詞**\n",
    "\n",
    "- 停用詞 = 某些NLP任務需要將一些常出现的“無意義”的詞去掉，比如：統計一篇文章頻率最高的100個詞，可能會有大量的“is”、\"a\"、\"the\" 這類詞，它們就是 stopwords\n",
    "\n",
    "- Nothing.\n",
    "-  To identify author from a sentence, some stopwords play an important role because one has specific usages of them.\n",
    "-   從句子中識別作者,某些停用詞有重要的作用,因為它們有特定的用法\n",
    "\n",
    "\n",
    "## **Stemming and Lowercase**\n",
    "- Stemming = 過去式,未來式變回原型\n",
    "- Lowercase = 轉小寫\n",
    "\n",
    "- Nothing.\n",
    "-   This reason is the same for stopwords removing.\n",
    "-   And I guess some stemming rules provided by libraries is bad for this task because all author is the older author.\n",
    "-   同樣是為了刪除停用詞\n",
    "-   我想 libraries 提供一些停用詞詞庫對這項任務不太有用,因為有些都是較老的作者\n",
    "\n",
    "## **Cutting long sentence**\n",
    "**切割較長的句子**\n",
    "\n",
    "-   Too long documents are cut.\n",
    "-   切割太長的文件\n",
    "\n",
    "## **Punctuation**\n",
    "**標點符號**\n",
    "\n",
    "-   Because I guess each author has unique punctuations's usage in the novel, I separate them from words.\n",
    "-   因為我猜作者在小說中都有獨特的標點符號用法,我把它們和文字分開\n",
    "\n",
    "- e.g. `Don't worry` -> `Don ' t worry`\n",
    "\n",
    "## **Is it slow?**\n",
    "\n",
    "- Don't worry! FastText is a very fast algorithm if it runs on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's check character distribution per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c MWS   EAP   HPL   \n",
      "e 97515 114885 88259 \n",
      "î 0 1 0 \n",
      "D 227 491 334 \n",
      "Σ 0 0 1 \n",
      "α 0 0 2 \n",
      "F 232 383 269 \n",
      "E 445 435 281 \n",
      "â 0 6 0 \n",
      "L 307 458 249 \n",
      "x 1267 1951 1061 \n",
      "Z 2 23 51 \n",
      "O 282 414 503 \n",
      "q 677 1030 779 \n",
      "Π 0 0 1 \n",
      "M 415 1065 645 \n",
      "C 308 395 439 \n",
      "A 943 1258 1167 \n",
      "G 246 313 318 \n",
      "m 20471 22792 17622 \n",
      "w 16062 17507 15554 \n",
      "à 0 10 0 \n",
      "P 365 442 320 \n",
      "l 27819 35371 30273 \n",
      "R 385 258 237 \n",
      "ü 0 1 5 \n",
      "ï 0 0 7 \n",
      "t 63142 82426 62235 \n",
      "δ 0 0 2 \n",
      "Ν 0 0 1 \n",
      "ä 0 1 6 \n",
      "z 400 634 529 \n",
      "ñ 0 0 7 \n",
      "\" 1469 2987 513 \n",
      "X 4 17 5 \n",
      "a 55274 68525 56815 \n",
      "n 50291 62636 50879 \n",
      "b 9611 13245 10636 \n",
      "Å 0 0 1 \n",
      "d 35315 36862 33366 \n",
      "Q 7 21 10 \n",
      "B 395 835 533 \n",
      "Υ 0 0 1 \n",
      ": 339 176 47 \n",
      "? 419 510 169 \n",
      "h 43738 51580 42770 \n",
      ", 12045 17594 8581 \n",
      "j 682 683 424 \n",
      "i 46080 60952 44250 \n",
      "N 204 411 345 \n",
      "é 0 47 15 \n",
      "K 35 86 176 \n",
      "s 45962 53841 43915 \n",
      "I 4917 4846 3480 \n",
      "V 57 156 67 \n",
      "J 66 164 210 \n",
      "g 12601 16088 14951 \n",
      "H 669 864 741 \n",
      "ô 0 8 0 \n",
      "Y 234 282 111 \n",
      "p 12361 17422 10965 \n",
      "; 2662 1354 1143 \n",
      "c 17911 24127 18338 \n",
      "y 14877 17001 12534 \n",
      "k 3707 4277 5204 \n",
      "ê 0 28 2 \n",
      ". 5761 8406 5908 \n",
      "Ο 0 0 3 \n",
      "ö 0 16 3 \n",
      "' 476 1334 1710 \n",
      "f 18351 22354 16272 \n",
      "Æ 0 1 4 \n",
      "è 0 15 0 \n",
      "o 53386 67145 50996 \n",
      "W 681 739 732 \n",
      "U 46 166 94 \n",
      "ë 0 0 12 \n",
      "v 7948 9624 6529 \n",
      "æ 0 36 10 \n",
      "u 21025 26311 19519 \n",
      "ἶ 0 0 2 \n",
      "ç 0 1 0 \n",
      "T 1230 2217 1583 \n",
      "r 44042 51221 40590 \n",
      "S 578 729 841 \n"
     ]
    }
   ],
   "source": [
    "# from collections import defaultdict\n",
    "# 跟dict用法一樣 但是可讀性更高\n",
    "# set() = 是一個無序不重複元素集, 集合型態\n",
    "counter = {name : defaultdict(int) for name in set(df.author)}\n",
    "for (text, author) in zip(df.text, df.author):\n",
    "    text = text.replace(' ', '')\n",
    "    for c in text:\n",
    "    # c = 88(0~87) , text =88\n",
    "        counter[author][c] += 1\n",
    "        # author = 'HPL'那些 , c (0~87)\n",
    "        # 迴圈剛好是把每個字切開 (text)\n",
    "        # 把zip裡面的文章內容(text) 出現的字 存進counter字典  這樣就有了每個字母出現的次數\n",
    "\n",
    "chars = set()\n",
    "# set() = 是一個無序不重複元素集, 集合型態\n",
    "for v in counter.values():\n",
    "# counter.values() =  每一個字典內容\n",
    "    \n",
    "    chars |= v.keys()\n",
    "    # v.keys() = 所有字典內容的字母\n",
    "    # chars 有了所有字典內的字母 但不重複\n",
    "    \n",
    "names = [author for author in counter.keys()]\n",
    "# counter.keys() = dict_keys(['MWS', 'EAP', 'HPL'])\n",
    "\n",
    "print('c ', end='')\n",
    "# end=' '意思是末尾不換行，加空格\n",
    "for n in names:\n",
    "    print(n, end='   ')\n",
    "print()\n",
    "for c in chars:    \n",
    "    print(c, end=' ')\n",
    "    for n in names:\n",
    "    # names = 3種作者(n) , c = 每一個字\n",
    "        print(counter[n][c], end=' ')\n",
    "        # counter[作者][字母] = 查詢到字典中 那一個作者中那一個字的出現次數\n",
    "    print()\n",
    "    \n",
    "#查詢到字典中 那一個作者中那一個字的出現次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HPL', defaultdict(int, {})),\n",
       " ('MWS', defaultdict(int, {})),\n",
       " ('EAP', defaultdict(int, {}))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 觀看字典內容 目前還沒有東西\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Helaidagnarledclawonmyshoulder,anditseemedtomethatitsshakingwasnotaltogetherthatofmirth.',\n",
       " 'HPL')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text , author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter['EAP']['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter['MWS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAP': defaultdict(int,\n",
       "             {'\"': 2987,\n",
       "              \"'\": 1334,\n",
       "              ',': 17594,\n",
       "              '.': 8406,\n",
       "              ':': 176,\n",
       "              ';': 1354,\n",
       "              '?': 510,\n",
       "              'A': 1258,\n",
       "              'B': 835,\n",
       "              'C': 395,\n",
       "              'D': 491,\n",
       "              'E': 435,\n",
       "              'F': 383,\n",
       "              'G': 313,\n",
       "              'H': 864,\n",
       "              'I': 4846,\n",
       "              'J': 164,\n",
       "              'K': 86,\n",
       "              'L': 458,\n",
       "              'M': 1065,\n",
       "              'N': 411,\n",
       "              'O': 414,\n",
       "              'P': 442,\n",
       "              'Q': 21,\n",
       "              'R': 258,\n",
       "              'S': 729,\n",
       "              'T': 2217,\n",
       "              'U': 166,\n",
       "              'V': 156,\n",
       "              'W': 739,\n",
       "              'X': 17,\n",
       "              'Y': 282,\n",
       "              'Z': 23,\n",
       "              'a': 68525,\n",
       "              'b': 13245,\n",
       "              'c': 24127,\n",
       "              'd': 36862,\n",
       "              'e': 114885,\n",
       "              'f': 22354,\n",
       "              'g': 16088,\n",
       "              'h': 51580,\n",
       "              'i': 60952,\n",
       "              'j': 683,\n",
       "              'k': 4277,\n",
       "              'l': 35371,\n",
       "              'm': 22792,\n",
       "              'n': 62636,\n",
       "              'o': 67145,\n",
       "              'p': 17422,\n",
       "              'q': 1030,\n",
       "              'r': 51221,\n",
       "              's': 53841,\n",
       "              't': 82426,\n",
       "              'u': 26311,\n",
       "              'v': 9624,\n",
       "              'w': 17507,\n",
       "              'x': 1951,\n",
       "              'y': 17001,\n",
       "              'z': 634,\n",
       "              'Æ': 1,\n",
       "              'à': 10,\n",
       "              'â': 6,\n",
       "              'ä': 1,\n",
       "              'æ': 36,\n",
       "              'ç': 1,\n",
       "              'è': 15,\n",
       "              'é': 47,\n",
       "              'ê': 28,\n",
       "              'î': 1,\n",
       "              'ô': 8,\n",
       "              'ö': 16,\n",
       "              'ü': 1}),\n",
       " 'HPL': defaultdict(int,\n",
       "             {'\"': 513,\n",
       "              \"'\": 1710,\n",
       "              ',': 8581,\n",
       "              '.': 5908,\n",
       "              ':': 47,\n",
       "              ';': 1143,\n",
       "              '?': 169,\n",
       "              'A': 1167,\n",
       "              'B': 533,\n",
       "              'C': 439,\n",
       "              'D': 334,\n",
       "              'E': 281,\n",
       "              'F': 269,\n",
       "              'G': 318,\n",
       "              'H': 741,\n",
       "              'I': 3480,\n",
       "              'J': 210,\n",
       "              'K': 176,\n",
       "              'L': 249,\n",
       "              'M': 645,\n",
       "              'N': 345,\n",
       "              'O': 503,\n",
       "              'P': 320,\n",
       "              'Q': 10,\n",
       "              'R': 237,\n",
       "              'S': 841,\n",
       "              'T': 1583,\n",
       "              'U': 94,\n",
       "              'V': 67,\n",
       "              'W': 732,\n",
       "              'X': 5,\n",
       "              'Y': 111,\n",
       "              'Z': 51,\n",
       "              'a': 56815,\n",
       "              'b': 10636,\n",
       "              'c': 18338,\n",
       "              'd': 33366,\n",
       "              'e': 88259,\n",
       "              'f': 16272,\n",
       "              'g': 14951,\n",
       "              'h': 42770,\n",
       "              'i': 44250,\n",
       "              'j': 424,\n",
       "              'k': 5204,\n",
       "              'l': 30273,\n",
       "              'm': 17622,\n",
       "              'n': 50879,\n",
       "              'o': 50996,\n",
       "              'p': 10965,\n",
       "              'q': 779,\n",
       "              'r': 40590,\n",
       "              's': 43915,\n",
       "              't': 62235,\n",
       "              'u': 19519,\n",
       "              'v': 6529,\n",
       "              'w': 15554,\n",
       "              'x': 1061,\n",
       "              'y': 12534,\n",
       "              'z': 529,\n",
       "              'Å': 1,\n",
       "              'Æ': 4,\n",
       "              'ä': 6,\n",
       "              'æ': 10,\n",
       "              'é': 15,\n",
       "              'ê': 2,\n",
       "              'ë': 12,\n",
       "              'ï': 7,\n",
       "              'ñ': 7,\n",
       "              'ö': 3,\n",
       "              'ü': 5,\n",
       "              'Ν': 1,\n",
       "              'Ο': 3,\n",
       "              'Π': 1,\n",
       "              'Σ': 1,\n",
       "              'Υ': 1,\n",
       "              'α': 2,\n",
       "              'δ': 2,\n",
       "              'ἶ': 2}),\n",
       " 'MWS': defaultdict(int,\n",
       "             {'\"': 1469,\n",
       "              \"'\": 476,\n",
       "              ',': 12045,\n",
       "              '.': 5761,\n",
       "              ':': 339,\n",
       "              ';': 2662,\n",
       "              '?': 419,\n",
       "              'A': 943,\n",
       "              'B': 395,\n",
       "              'C': 308,\n",
       "              'D': 227,\n",
       "              'E': 445,\n",
       "              'F': 232,\n",
       "              'G': 246,\n",
       "              'H': 669,\n",
       "              'I': 4917,\n",
       "              'J': 66,\n",
       "              'K': 35,\n",
       "              'L': 307,\n",
       "              'M': 415,\n",
       "              'N': 204,\n",
       "              'O': 282,\n",
       "              'P': 365,\n",
       "              'Q': 7,\n",
       "              'R': 385,\n",
       "              'S': 578,\n",
       "              'T': 1230,\n",
       "              'U': 46,\n",
       "              'V': 57,\n",
       "              'W': 681,\n",
       "              'X': 4,\n",
       "              'Y': 234,\n",
       "              'Z': 2,\n",
       "              'a': 55274,\n",
       "              'b': 9611,\n",
       "              'c': 17911,\n",
       "              'd': 35315,\n",
       "              'e': 97515,\n",
       "              'f': 18351,\n",
       "              'g': 12601,\n",
       "              'h': 43738,\n",
       "              'i': 46080,\n",
       "              'j': 682,\n",
       "              'k': 3707,\n",
       "              'l': 27819,\n",
       "              'm': 20471,\n",
       "              'n': 50291,\n",
       "              'o': 53386,\n",
       "              'p': 12361,\n",
       "              'q': 677,\n",
       "              'r': 44042,\n",
       "              's': 45962,\n",
       "              't': 63142,\n",
       "              'u': 21025,\n",
       "              'v': 7948,\n",
       "              'w': 16062,\n",
       "              'x': 1267,\n",
       "              'y': 14877,\n",
       "              'z': 400})}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字典有了每個字母出現的次數\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([defaultdict(<class 'int'>, {'Q': 7, '.': 5761, 'i': 46080, 'F': 232, 'L': 307, ',': 12045, \"'\": 476, 'Z': 2, 'v': 7948, 'O': 282, '?': 419, 'o': 53386, 'H': 669, 'b': 9611, 'r': 44042, 'Y': 234, 'u': 21025, 'X': 4, 'j': 682, 'p': 12361, ':': 339, 'B': 395, 'M': 415, 't': 63142, 'w': 16062, 'y': 14877, 'f': 18351, 'V': 57, '\"': 1469, 'J': 66, 'g': 12601, 'k': 3707, 'U': 46, 'A': 943, 'x': 1267, 's': 45962, 'D': 227, 'n': 50291, 'c': 17911, 'd': 35315, 'R': 385, 0: 0, 'E': 445, 'W': 681, 'C': 308, ';': 2662, 'h': 43738, 'S': 578, 'T': 1230, 'K': 35, 'q': 677, 'I': 4917, 'P': 365, 'z': 400, 'a': 55274, 'N': 204, 'l': 27819, 'm': 20471, 'G': 246, 'e': 97515}), defaultdict(<class 'int'>, {'Q': 21, '.': 8406, 'i': 60952, 'F': 383, 'â': 6, 'L': 458, ',': 17594, \"'\": 1334, 'Z': 23, 'é': 47, 'à': 10, 'v': 9624, 'O': 414, '?': 510, 'o': 67145, 'H': 864, 'b': 13245, 'r': 51221, 'Y': 282, 'u': 26311, 'X': 17, 'j': 683, 'p': 17422, ':': 176, 'B': 835, 'I': 4846, 't': 82426, 'Æ': 1, 'w': 17507, 'y': 17001, 'f': 22354, 'ô': 8, 'V': 156, '\"': 2987, 'm': 22792, 'g': 16088, 'æ': 36, 'k': 4277, 'U': 166, 'A': 1258, 'x': 1951, 's': 53841, 'î': 1, 'n': 62636, 'c': 24127, 'ê': 28, 'd': 36862, 'R': 258, 'E': 435, 'ç': 1, 'W': 739, 'C': 395, ';': 1354, 'è': 15, 'D': 491, 'S': 729, 'ä': 1, 'T': 2217, 'K': 86, 'q': 1030, 'M': 1065, 'P': 442, 'J': 164, 'z': 634, 'a': 68525, 'N': 411, 'l': 35371, 'h': 51580, 'G': 313, 'ö': 16, 'e': 114885, 'ü': 1}), defaultdict(<class 'int'>, {'Q': 10, '.': 5908, 'i': 44250, 'F': 269, 1: 0, 'L': 249, ',': 8581, 87: 0, \"'\": 1710, 'Z': 51, 'δ': 2, 'v': 6529, 'O': 503, '?': 169, 'o': 50996, 'H': 741, 'b': 10636, 'r': 40590, 'Y': 111, 'u': 19519, 'ἶ': 2, 'Υ': 1, 'X': 5, 'æ': 10, 'p': 10965, ':': 47, 'B': 533, 'M': 645, 't': 62235, 'N': 345, 'w': 15554, 'y': 12534, 'f': 16272, 'V': 67, '\"': 513, 'J': 210, 'α': 2, 'Σ': 1, 'g': 14951, 'é': 15, 'k': 5204, 'U': 94, 'A': 1167, 'x': 1061, 's': 43915, 'D': 334, 'n': 50879, 'c': 18338, 'ê': 2, 'd': 33366, 'R': 237, 'Π': 1, 'E': 281, 'W': 732, 'C': 439, ';': 1143, 'h': 42770, 'S': 841, 'ä': 6, 'ï': 7, 'Ν': 1, 88: 0, 'T': 1583, 'ñ': 7, 'K': 176, 'q': 779, 'I': 3480, 'Ο': 3, 'P': 320, 100: 0, 'ë': 12, 'Æ': 4, 'z': 529, 'a': 56815, 'j': 424, 'l': 30273, 'm': 17622, 'G': 318, 0: 0, 'ö': 3, 'e': 88259, 'Å': 1, 'ü': 5})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MWS', 'EAP', 'HPL'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Q', '.', 'i', 'F', 1, 'L', ',', 87, \"'\", 'Z', 'δ', 'v', 'O', '?', 'o', 'H', 'b', 'r', 'Y', 'u', 'ἶ', 'Υ', 'X', 'æ', 'p', ':', 'B', 'M', 't', 'N', 'w', 'y', 'f', 'V', '\"', 'J', 'α', 'Σ', 'g', 'é', 'k', 'U', 'A', 'x', 's', 'D', 'n', 'c', 'ê', 'd', 'R', 'Π', 'E', 'W', 'C', ';', 'h', 'S', 'ä', 'ï', 'Ν', 88, 'T', 'ñ', 'K', 'q', 'I', 'Ο', 'P', 100, 'ë', 'Æ', 'z', 'a', 'j', 'l', 'm', 'G', 0, 'ö', 'e', 'Å', 'ü'])\n"
     ]
    }
   ],
   "source": [
    "# chars 加入這些\n",
    "print(v.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " '.',\n",
       " 1,\n",
       " ',',\n",
       " 'Z',\n",
       " 'δ',\n",
       " 'à',\n",
       " 'ö',\n",
       " 'b',\n",
       " 'r',\n",
       " 'ἶ',\n",
       " ':',\n",
       " 'B',\n",
       " 'I',\n",
       " 'Æ',\n",
       " 'w',\n",
       " 'y',\n",
       " 'f',\n",
       " 'k',\n",
       " 'x',\n",
       " 's',\n",
       " 'O',\n",
       " 'X',\n",
       " 'ê',\n",
       " 'Υ',\n",
       " 'd',\n",
       " 'E',\n",
       " 'C',\n",
       " ';',\n",
       " 'D',\n",
       " 'h',\n",
       " 'S',\n",
       " 'ï',\n",
       " 87,\n",
       " 88,\n",
       " 'T',\n",
       " 'K',\n",
       " 'Ο',\n",
       " 'é',\n",
       " 100,\n",
       " 'ë',\n",
       " 'Y',\n",
       " 'N',\n",
       " 'Ν',\n",
       " 'm',\n",
       " 'U',\n",
       " 'Π',\n",
       " 'Q',\n",
       " 'i',\n",
       " 'F',\n",
       " 'â',\n",
       " \"'\",\n",
       " 'v',\n",
       " '?',\n",
       " 'o',\n",
       " 'H',\n",
       " 'u',\n",
       " 'R',\n",
       " 'p',\n",
       " 'ç',\n",
       " 'M',\n",
       " 't',\n",
       " 'j',\n",
       " 'G',\n",
       " 'æ',\n",
       " 'ô',\n",
       " 'V',\n",
       " 'Σ',\n",
       " 'g',\n",
       " 'A',\n",
       " 'e',\n",
       " 'Å',\n",
       " 'î',\n",
       " 'n',\n",
       " 'c',\n",
       " '\"',\n",
       " 'α',\n",
       " 'W',\n",
       " 'ä',\n",
       " 'ñ',\n",
       " 'q',\n",
       " 'P',\n",
       " 'L',\n",
       " 'z',\n",
       " 'a',\n",
       " 'l',\n",
       " 'J',\n",
       " 'è',\n",
       " 'ü'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chars 有了所有字典內的字母 但不重複\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary of character distribution**\n",
    "**總結字元內容**\n",
    "\n",
    "- HPL and EAP used non ascii characters like a `ä`.\n",
    "- HPL 和 EAP 有使用非ascii 字符  like a `ä`.\n",
    "\n",
    "- The number of punctuations seems to be good feature\n",
    "- 標點符號是很好的特徵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "My preproceeings are \n",
    "\n",
    "- Separate punctuation from words\n",
    "- 切割標點符號\n",
    "- Remove lower frequency words ( <= 2)\n",
    "- 刪除詞頻<=2 \n",
    "- Cut a longer document which contains `256` words\n",
    "- 切割過長的文章, 256字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 這邊要切割標點符號\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    # 把'符號 變成 前後都有空白\n",
    "    signs = set(',.:;\"?!')\n",
    "    prods = set(text) & signs\n",
    "    if not prods:\n",
    "    #如果內容沒有(',.:;\"?!') 這些符號 直接回傳text\n",
    "        return text\n",
    "\n",
    "    for sign in prods:\n",
    "    # sign= (',.:;\"?!') in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "        # text = 把sign 格式化 一連串符號變成一個{} , 並且{}不指定位置 , {}可以填入變成{0}\n",
    "        # prods 內容是{,.,} 那些\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 這邊要刪除詞頻<=2\n",
    "\n",
    "def create_docs(df, n_gram_max=2):\n",
    "    def add_ngram(q, n_gram_max):\n",
    "            ngrams = []\n",
    "            for n in range(2, n_gram_max+1):\n",
    "                # n_gram_max = 3 , n=2\n",
    "                for w_index in range(len(q)-n+1):\n",
    "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n",
    "            return q + ngrams\n",
    "    docs = []\n",
    "    for doc in df.text:\n",
    "        doc = preprocess(doc).split()\n",
    "        # preprocess = 標準化\n",
    "        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 這邊要切割過長的文章\n",
    "\n",
    "min_count = 2\n",
    "\n",
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=False, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "# fit_on_text(texts) = 使用一系列的檔案來生成token字典，texts為list類，每個元素為一個檔案\n",
    "\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=False, filters='')\n",
    "\n",
    "tokenizer.fit_on_texts(docs)\n",
    "\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "# texts_to_sequences = 將多個檔案轉換為word下標的向量形式\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "# maxlen：None或整数，為序列的最大長度\n",
    "# 其他短於長度的該序都會在後面填充0以達到該長度\n",
    "# 長於 maxlen 的序列都會被截斷 , 以使其批配目標長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Model: FastText by Keras**\n",
    "\n",
    "FastText is very fast and strong baseline algorithm for text classification based on Continuous Bag-of-Words model a.k.a Word2vec.\n",
    "\n",
    "FastText contains only three layers:\n",
    "\n",
    "1. Embeddings layer: Input words (and word n-grams) are all words in a sentence/document\n",
    "2. Mean/AveragePooling Layer: Taking average vector of Embedding vectors\n",
    "3. Softmax layer\n",
    "\n",
    "There are some implementations of FastText:\n",
    "\n",
    "- Original library provided by Facebook AI research: https://github.com/facebookresearch/fastText\n",
    "- Keras: https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py\n",
    "- Gensim: https://radimrehurek.com/gensim/models/wrappers/fasttext.html\n",
    "\n",
    "Original Paper: https://arxiv.org/abs/1607.01759 : More detail information about fastText classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My FastText parameters are:\n",
    "\n",
    "- The dimension of word vector is 20\n",
    "- Optimizer is `Adam`\n",
    "- Inputs are words and word bi-grams\n",
    "  - you can change this parameter by passing the max n-gram size to argument of `create_docs` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = np.max(docs) + 1\n",
    "embedding_dims = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(embedding_dims=20, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(3, activation='softmax'))  #(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/25\n",
      "15663/15663 [==============================] - 68s 4ms/step - loss: 1.0678 - acc: 0.4075 - val_loss: 1.0307 - val_acc: 0.4535\n",
      "Epoch 2/25\n",
      "15663/15663 [==============================] - 91s 6ms/step - loss: 0.9350 - acc: 0.6098 - val_loss: 0.8613 - val_acc: 0.7142\n",
      "Epoch 3/25\n",
      "15663/15663 [==============================] - 91s 6ms/step - loss: 0.7280 - acc: 0.7850 - val_loss: 0.7093 - val_acc: 0.7554\n",
      "Epoch 4/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.5687 - acc: 0.8461 - val_loss: 0.6116 - val_acc: 0.7868\n",
      "Epoch 5/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.4550 - acc: 0.8794 - val_loss: 0.5420 - val_acc: 0.8036\n",
      "Epoch 6/25\n",
      "15663/15663 [==============================] - 92s 6ms/step - loss: 0.3687 - acc: 0.9061 - val_loss: 0.4893 - val_acc: 0.8192\n",
      "Epoch 7/25\n",
      "15663/15663 [==============================] - 92s 6ms/step - loss: 0.3009 - acc: 0.9275 - val_loss: 0.4521 - val_acc: 0.8297\n",
      "Epoch 8/25\n",
      "15663/15663 [==============================] - 92s 6ms/step - loss: 0.2467 - acc: 0.9441 - val_loss: 0.4204 - val_acc: 0.8447\n",
      "Epoch 9/25\n",
      "15663/15663 [==============================] - 91s 6ms/step - loss: 0.2026 - acc: 0.9574 - val_loss: 0.3992 - val_acc: 0.8450\n",
      "Epoch 10/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.1668 - acc: 0.9663 - val_loss: 0.3864 - val_acc: 0.8475\n",
      "Epoch 11/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.1369 - acc: 0.9742 - val_loss: 0.3669 - val_acc: 0.8593\n",
      "Epoch 12/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.1128 - acc: 0.9800 - val_loss: 0.3601 - val_acc: 0.8631\n",
      "Epoch 13/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.0928 - acc: 0.9848 - val_loss: 0.3489 - val_acc: 0.8682\n",
      "Epoch 14/25\n",
      "15663/15663 [==============================] - 90s 6ms/step - loss: 0.0770 - acc: 0.9876 - val_loss: 0.3440 - val_acc: 0.8685\n",
      "Epoch 15/25\n",
      "15663/15663 [==============================] - 52s 3ms/step - loss: 0.0635 - acc: 0.9905 - val_loss: 0.3421 - val_acc: 0.8677\n",
      "Epoch 16/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 0.0527 - acc: 0.9921 - val_loss: 0.3426 - val_acc: 0.8693\n",
      "Epoch 17/25\n",
      "15663/15663 [==============================] - 35s 2ms/step - loss: 0.0437 - acc: 0.9937 - val_loss: 0.3474 - val_acc: 0.8670\n",
      "CPU times: user 3min 35s, sys: 2min 6s, total: 5min 41s\n",
      "Wall time: 22min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 25\n",
    "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# 當監測不再改善時,該回調函數將中止訓練\n",
    "# monitor = 需要監視的量\n",
    "# patience = 當early stop被啟動（如發現loss相比上一個epoch訓練沒有下降），則經過patience個epoch後停止訓練\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=epochs,\n",
    "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.1 Change Preprocessings**\n",
    "\n",
    "Next, I change some parameters and preprocessings to improve fastText model.\n",
    "## **2.1.1 Do lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = create_docs(df)\n",
    "tokenizer = Tokenizer(lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "\n",
    "input_dim = np.max(docs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/16\n",
      "15663/15663 [==============================] - 39s 2ms/step - loss: 1.0667 - acc: 0.4096 - val_loss: 1.0267 - val_acc: 0.4216\n",
      "Epoch 2/16\n",
      "15663/15663 [==============================] - 31s 2ms/step - loss: 0.9261 - acc: 0.6157 - val_loss: 0.8504 - val_acc: 0.6790\n",
      "Epoch 3/16\n",
      "15663/15663 [==============================] - 34s 2ms/step - loss: 0.7231 - acc: 0.7848 - val_loss: 0.7020 - val_acc: 0.7620\n",
      "Epoch 4/16\n",
      "15663/15663 [==============================] - 37s 2ms/step - loss: 0.5691 - acc: 0.8385 - val_loss: 0.6018 - val_acc: 0.7939\n",
      "Epoch 5/16\n",
      "15663/15663 [==============================] - 33s 2ms/step - loss: 0.4585 - acc: 0.8751 - val_loss: 0.5352 - val_acc: 0.8098\n",
      "Epoch 6/16\n",
      "15663/15663 [==============================] - 23s 1ms/step - loss: 0.3746 - acc: 0.9013 - val_loss: 0.4829 - val_acc: 0.8322\n",
      "Epoch 7/16\n",
      "15663/15663 [==============================] - 19s 1ms/step - loss: 0.3080 - acc: 0.9231 - val_loss: 0.4453 - val_acc: 0.8414\n",
      "Epoch 8/16\n",
      "15663/15663 [==============================] - 20s 1ms/step - loss: 0.2545 - acc: 0.9379 - val_loss: 0.4154 - val_acc: 0.8468\n",
      "Epoch 9/16\n",
      "15663/15663 [==============================] - 19s 1ms/step - loss: 0.2103 - acc: 0.9536 - val_loss: 0.3947 - val_acc: 0.8486\n",
      "Epoch 10/16\n",
      "15663/15663 [==============================] - 19s 1ms/step - loss: 0.1744 - acc: 0.9634 - val_loss: 0.3748 - val_acc: 0.8550\n",
      "Epoch 11/16\n",
      "15663/15663 [==============================] - 18s 1ms/step - loss: 0.1448 - acc: 0.9702 - val_loss: 0.3635 - val_acc: 0.8575\n",
      "Epoch 12/16\n",
      "15663/15663 [==============================] - 18s 1ms/step - loss: 0.1206 - acc: 0.9770 - val_loss: 0.3507 - val_acc: 0.8613\n",
      "Epoch 13/16\n",
      "15663/15663 [==============================] - 37s 2ms/step - loss: 0.0999 - acc: 0.9807 - val_loss: 0.3440 - val_acc: 0.8631\n",
      "Epoch 14/16\n",
      "15663/15663 [==============================] - 37s 2ms/step - loss: 0.0838 - acc: 0.9854 - val_loss: 0.3424 - val_acc: 0.8631\n",
      "Epoch 15/16\n",
      "15663/15663 [==============================] - 39s 2ms/step - loss: 0.0698 - acc: 0.9879 - val_loss: 0.3351 - val_acc: 0.8677\n",
      "Epoch 16/16\n",
      "15663/15663 [==============================] - 39s 2ms/step - loss: 0.0586 - acc: 0.9912 - val_loss: 0.3425 - val_acc: 0.8644\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n",
    "\n",
    "model = create_model()\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=epochs,\n",
    "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./keras_fasttext_data/test.zip')\n",
    "docs = create_docs(test_df)\n",
    "# 丟入test資料集\n",
    "docs = tokenizer.texts_to_sequences(docs)\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n",
    "y = model.predict_proba(docs)\n",
    "# 預測可能的\n",
    "\n",
    "result = pd.read_csv('./keras_fasttext_data/sample_submission.zip')\n",
    "for a, i in a2c.items():\n",
    "    result[a] = y[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('./keras_fasttext_data/kefastText_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('MWS', 2), ('EAP', 0), ('HPL', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
